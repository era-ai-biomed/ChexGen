model = dict(
    class_dropout_prob=0.1,
    grad_cal_steps=1,
    grad_checkpoint=True,
    input_size=64,
    pos_embed_scale=2.0,
    token_num=120,
    type='DiT_XL_2',
    use_fp32_attn=True
)
